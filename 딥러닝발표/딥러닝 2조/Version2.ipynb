{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Version2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "my-V7clMMl-x"
      },
      "source": [
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "    IS_COLAB = True\n",
        "except Exception:\n",
        "    IS_COLAB = False\n",
        "\n",
        "# TensorFlow ≥2.0 is required\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "assert tf.__version__ >= \"2.0\"\n",
        "\n",
        "if not tf.test.is_gpu_available():\n",
        "    print(\"No GPU was detected. CNNs can be very slow without a GPU.\")\n",
        "    if IS_COLAB:\n",
        "        print(\"Go to Runtime > Change runtime and select a GPU hardware accelerator.\")\n",
        "\n",
        "import keras \n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Dropout, Input, MaxPooling2D,ZeroPadding2D,Conv2DTranspose, concatenate\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from tqdm import tqdm \n",
        "import numpy as np\n",
        "import os\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRnBge9tMkFe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veZQG8t_MkCE"
      },
      "source": [
        "def sorted_alphanumeric(data):  \n",
        "    convert = lambda text: int(text) if text.isdigit() else text.lower()\n",
        "    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)',key)]\n",
        "    return sorted(data,key = alphanum_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34Vtc8lbMqXF"
      },
      "source": [
        "# defining the size of image \n",
        "SIZE = 128\n",
        "\n",
        "mask_path =  '/content/drive/MyDrive/mask_data/mask_train_gunny/'\n",
        "mask_array_train = []\n",
        "\n",
        "image_path = '/content/drive/MyDrive/mask_data/no_mask_train_gunny/'\n",
        "img_array_train = []\n",
        "\n",
        "image_file = sorted_alphanumeric(os.listdir(image_path))\n",
        "mask_file = sorted_alphanumeric(os.listdir(mask_path))\n",
        "for i in tqdm(mask_file):\n",
        "    #here i have only load 2500 images.\n",
        "    if i == 'with-mask-default-mask-seed2500.png':\n",
        "        break\n",
        "    else:    \n",
        "        image = cv2.imread(mask_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "        image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "        image = image.astype('float32') / 255.0\n",
        "\n",
        "        #appending normal normal image    \n",
        "        mask_array_train.append(img_to_array(image))\n",
        "\n",
        "  \n",
        "    \n",
        "for i in tqdm(image_file):\n",
        "  if i == 'seed2500.png':\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    image = cv2.imread(image_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "    image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "    image = image.astype('float32') / 255.0\n",
        "        # appending normal sketch image\n",
        "    img_array_train.append(img_to_array(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhgdH_oAHVsT"
      },
      "source": [
        "# defining the size of image \n",
        "SIZE = 128\n",
        "\n",
        "mask_path =  '/content/drive/MyDrive/mask_data/mask_val/'\n",
        "mask_array_val = []\n",
        "\n",
        "image_path = '/content/drive/MyDrive/mask_data/no_mask_val/'\n",
        "img_array_val = []\n",
        "\n",
        "image_file = sorted_alphanumeric(os.listdir(image_path))\n",
        "mask_file = sorted_alphanumeric(os.listdir(mask_path))\n",
        "for i in tqdm(mask_file):\n",
        "    #here i have only load 2500 images.\n",
        "    if i == 'with-mask-default-mask-seed2500.png':\n",
        "        break\n",
        "    else:    \n",
        "        image = cv2.imread(mask_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "        image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "        image = image.astype('float32') / 255.0\n",
        "\n",
        "        #appending normal normal image    \n",
        "        mask_array_test_gunny.append(img_to_array(image))\n",
        "\n",
        "  \n",
        "    \n",
        "for i in tqdm(image_file):\n",
        "  if i == 'seed2500.png':\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    image = cv2.imread(image_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "    image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "    image = image.astype('float32') / 255.0\n",
        "        # appending normal sketch image\n",
        "    img_array_val.append(img_to_array(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2KgfZ6IMqRc"
      },
      "source": [
        "# defining the size of image \n",
        "SIZE = 128\n",
        "\n",
        "mask_path =  '/content/drive/MyDrive/mask_data/mask_train_test/'\n",
        "mask_array_test = []\n",
        "\n",
        "image_path = '/content/drive/MyDrive/mask_data/no_mask_train_test/'\n",
        "img_array_test = []\n",
        "\n",
        "image_file = sorted_alphanumeric(os.listdir(image_path))\n",
        "mask_file = sorted_alphanumeric(os.listdir(mask_path))\n",
        "for i in tqdm(mask_file):\n",
        "    #here i have only load 2500 images.\n",
        "    if i == 'with-mask-default-mask-seed2500.png':\n",
        "        break\n",
        "    else:    \n",
        "        image = cv2.imread(mask_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "        image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "        image = image.astype('float32') / 255.0\n",
        "\n",
        "        #appending normal normal image    \n",
        "        mask_array_test_gunny.append(img_to_array(image))\n",
        "\n",
        "  \n",
        "    \n",
        "for i in tqdm(image_file):\n",
        "  if i == 'seed2500.png':\n",
        "    break\n",
        "\n",
        "  else:\n",
        "    image = cv2.imread(image_path + '/' + i,1)\n",
        "\n",
        "        # as opencv load image in bgr format converting it to rgb\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # resizing images \n",
        "    image = cv2.resize(image, (SIZE, SIZE))\n",
        "\n",
        "        # normalizing image \n",
        "    image = image.astype('float32') / 255.0\n",
        "        # appending normal sketch image\n",
        "    img_array_val.append(img_to_array(image))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rl-j4AqMqOi"
      },
      "source": [
        "def plot_image_pair_test(test_predict, start, end):\n",
        "    for i in range(start, end):\n",
        "        plt.figure(figsize = (7,7))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.title(\"Mask\", fontsize = 15)\n",
        "        plt.imshow(test_mask_image[i].reshape(SIZE, SIZE, 3))\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.title(\"No Mask\", fontsize = 15)\n",
        "        plt.imshow(test_image[i].reshape(SIZE, SIZE, 3))\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.title('Predict', fontsize = 15)\n",
        "        plt.imshow(test_predict[i].reshape(SIZE,SIZE,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9lOX7lDMqLu"
      },
      "source": [
        "def plot_image_pair(images = 5):\n",
        "    for i in range(images):\n",
        "        plt.figure(figsize = (7,7))\n",
        "        plt.subplot(1,2,1)\n",
        "        plt.title(\"No Mask\", fontsize = 15)\n",
        "        plt.imshow(img_array_test_gunny[i].reshape(SIZE, SIZE, 3))\n",
        "        plt.subplot(1,2,2)\n",
        "        plt.title(\"Mask\", fontsize = 15)\n",
        "        plt.imshow(mask_array_test_gunny[i].reshape(SIZE, SIZE, 3))\n",
        "        \n",
        "        \n",
        "        \n",
        "plot_image_pair(11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvKERmxTHf7O"
      },
      "source": [
        "train_mask_image = mask_array[:3500]\n",
        "train_image = img_array[:3500]\n",
        "\n",
        "val_mask_image = mask_array_val[:500]\n",
        "val_image = img_array_val[:500]\n",
        "\n",
        "test_mask_image = mask_array_test[:500]\n",
        "test_image = img_array_test[:500]\n",
        "\n",
        "\n",
        "# reshaping\n",
        "train_mask_image = np.reshape(train_mask_image,(len(train_mask_image),SIZE,SIZE,3))\n",
        "train_image = np.reshape(train_image, (len(train_image),SIZE,SIZE,3))\n",
        "print('Train no mask image shape:',train_image.shape)\n",
        "\n",
        "val_mask_image = np.reshape(val_mask_image,(len(val_mask_image),SIZE,SIZE,3))\n",
        "val_image = np.reshape(val_image, (len(val_image),SIZE,SIZE,3))\n",
        "print('Validation no mask image shape:',val_image.shape)\n",
        "\n",
        "test_mask_image = np.reshape(test_mask_image,(len(test_mask_image),SIZE,SIZE,3))\n",
        "test_image = np.reshape(test_image, (len(test_image),SIZE,SIZE,3))\n",
        "print('Test no mask image shape',test_image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-4UIjya11wz"
      },
      "source": [
        "def SSIM(reconstructed, truth):\n",
        "    return tf.image.ssim(reconstructed, truth, 1.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD3WMtPfIUzr"
      },
      "source": [
        "# 새 섹션"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QeMA4izIXK0"
      },
      "source": [
        "# Unet case 1 (Optimizer : SGD, Learning rate : 0.01, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwbrL_OOvvDx"
      },
      "source": [
        "#unet\n",
        "\n",
        "inputs = Input((SIZE, SIZE, 3))\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "conv10 = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(conv9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXjvdNqLvzlY"
      },
      "source": [
        "unet_v1 = keras.Model(inputs=[inputs], outputs=[conv10])\n",
        "unet_v1.compile(optimizer=keras.optimizers.SGD(lr = 0.01), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoWW4p1XwbBQ"
      },
      "source": [
        "history = unet_v1.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifrPeRL6JHNH"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAE_RWxhJXvA"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjVoougD1qrV",
        "outputId": "8f248956-f90b-4e85-acfc-92a8b6b5c161"
      },
      "source": [
        "loss_acc= unet_v1.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0109 - SSIM: 0.5329\n",
            "MSE:  0.010918396525084972\n",
            "SSIM:  (0.532894492149353, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkwyduiaSrng"
      },
      "source": [
        "test_predict = unet_v1.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMhj_Rv7Occs"
      },
      "source": [
        "# Unet case 2 (Optimizer : ADAM, Learning rate : 0.001, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7RqXHrrNVpW"
      },
      "source": [
        "unet_v2 = keras.Model(inputs=[inputs], outputs=[conv10])\n",
        "unet_v2.compile(optimizer=keras.optimizers.Adam(lr = 0.001), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTkW87k2Nk__"
      },
      "source": [
        "history = unet_v2.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0IaraVuNlDG"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXwNZvdJNlHT"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eusgXBmvNlTB"
      },
      "source": [
        "loss_acc= unet_v2.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN-PpGz5Nla6"
      },
      "source": [
        "test_predict = unet_v2.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA1VIkaqOV11"
      },
      "source": [
        "# Unet case 3 (Optimizer : RMSProp, Learning rate : 0.001, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYCg5iqQNVmf"
      },
      "source": [
        "unet_v3 = keras.Model(inputs=[inputs], outputs=[conv10])\n",
        "unet_v3.compile(optimizer=keras.optimizers.RMSprop(lr = 0.001), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9N7Gx5QNVjb"
      },
      "source": [
        "history = unet_v3.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dww3tUYBNVah"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuBNmC3EO1NH"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlXnvgymO1Kb"
      },
      "source": [
        "loss_acc= unet_v3.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDr6QcuwO1IU"
      },
      "source": [
        "test_predict = unet_v3.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cj0sr10QO8ia"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Image Denoising Auto Encoder case1(Optimizer : SGD, Learning rate : 0.001, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUY_OdZ-PkEy"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEq5BDoaPktG"
      },
      "source": [
        "# Image Denoising Auto Encoder case1(Optimizer : SGD, Learning rate : 0.01, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kgfI0FoO1FS"
      },
      "source": [
        "encoder_input = keras.Input(shape=(SIZE,SIZE, 3), name=\"img\")\n",
        "\n",
        "conv1 = Conv2D(filters = 64, kernel_size = (3,3), padding = 'same')(encoder_input)\n",
        "conv1 = tf.keras.layers.LeakyReLU()(conv1)\n",
        "conv1 = tf.keras.layers.Dropout(0.2)(conv1)\n",
        "conv1 = tf.keras.layers.BatchNormalization()(conv1)\n",
        "\n",
        "conv2 = Conv2D(filters = 64,kernel_size = (3,3), strides = 2, padding = 'same')(conv1)\n",
        "conv2 = tf.keras.layers.LeakyReLU()(conv2)\n",
        "conv2 = tf.keras.layers.Dropout(0.2)(conv2)\n",
        "conv2 = tf.keras.layers.BatchNormalization()(conv2)\n",
        "\n",
        "conv3 = Conv2D(filters = 128,kernel_size = (5,5), strides = 2, padding = 'same')(conv2)\n",
        "conv3 = tf.keras.layers.LeakyReLU()(conv3)\n",
        "conv3 = tf.keras.layers.Dropout(0.2)(conv3)\n",
        "conv3 = tf.keras.layers.BatchNormalization()(conv3)\n",
        "\n",
        "conv4 = Conv2D(filters = 128, kernel_size = (3,3), padding = 'same')(conv3)\n",
        "conv4 = tf.keras.layers.LeakyReLU()(conv4)\n",
        "conv4 = tf.keras.layers.Dropout(0.2)(conv4)\n",
        "conv4 = tf.keras.layers.BatchNormalization()(conv4)\n",
        "\n",
        "conv5 = Conv2D(filters = 256, kernel_size = (5,5), strides = 2, padding = 'same')(conv4)\n",
        "conv5 = tf.keras.layers.LeakyReLU()(conv5)\n",
        "conv5 = tf.keras.layers.Dropout(0.2)(conv5)\n",
        "conv5 = tf.keras.layers.BatchNormalization()(conv5)\n",
        "\n",
        "encoder_output = Conv2D(filters = 512 , kernel_size = (3,3), strides = 2, padding = 'same')(conv5) \n",
        "encoder = tf.keras.Model(encoder_input, encoder_output)\n",
        "\n",
        "\n",
        "\n",
        "decoder_input = Conv2DTranspose(filters = 512 ,kernel_size = (3,3), strides = 2, padding = 'same')(encoder_output)\n",
        "\n",
        "skip1 = tf.keras.layers.concatenate([decoder_input, conv5])\n",
        "conv7 = Conv2D(256, 3, strides=1, padding='same')(skip1)\n",
        "conv7 = tf.keras.layers.LeakyReLU()(conv7)\n",
        "conv7 = tf.keras.layers.Dropout(0.2)(conv7)\n",
        "conv7 = tf.keras.layers.BatchNormalization()(conv7)\n",
        "deconv2 = Conv2DTranspose(128, 3, strides=2, padding='same')(conv7)\n",
        "deconv2 = tf.keras.layers.LeakyReLU()(deconv2)\n",
        "deconv2 = tf.keras.layers.Dropout(0.2)(deconv2)\n",
        "deconv2 = tf.keras.layers.BatchNormalization()(deconv2)\n",
        "\n",
        "skip2 = tf.keras.layers.concatenate([deconv2, conv3])\n",
        "conv8 = Conv2D(128, 5, strides=1, padding='same')(skip2)\n",
        "conv8 = tf.keras.layers.LeakyReLU()(conv8)\n",
        "conv8 = tf.keras.layers.Dropout(0.2)(conv8)\n",
        "conv8 = tf.keras.layers.BatchNormalization()(conv8)\n",
        "deconv3 = Conv2DTranspose(64, 3, strides=2, padding='same')(conv8)\n",
        "deconv3 = tf.keras.layers.LeakyReLU()(deconv3)\n",
        "deconv3 = tf.keras.layers.Dropout(0.2)(deconv3)\n",
        "deconv3 = tf.keras.layers.BatchNormalization()(deconv3)\n",
        "\n",
        "skip3 = tf.keras.layers.concatenate([deconv3, conv2])\n",
        "conv9 = Conv2D(64, 5, strides=1, padding='same')(skip3)\n",
        "conv9 = tf.keras.layers.LeakyReLU()(conv9)\n",
        "conv9 = tf.keras.layers.Dropout(0.2)(conv9)\n",
        "conv9 = tf.keras.layers.BatchNormalization()(conv9)\n",
        "deconv4 = Conv2DTranspose(64, 3, strides=2, padding='same')(conv9)\n",
        "deconv4 = tf.keras.layers.LeakyReLU()(deconv4)\n",
        "deconv4 = tf.keras.layers.Dropout(0.2)(deconv4)\n",
        "deconv4 = tf.keras.layers.BatchNormalization()(deconv4)\n",
        "\n",
        "skip4 = tf.keras.layers.concatenate([deconv4, conv1])\n",
        "decoder_output = Conv2D(3, 3, strides=1, padding='same', activation='sigmoid', kernel_initializer='orthogonal')(skip4)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbEfCiQ4QG6a"
      },
      "source": [
        "DeNoise_v1 = keras.Model(encoder_input, decoder_output)\n",
        "DeNoise_v1.compile(optimizer=keras.optimizers.SGD(lr = 0.01), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XziC3EE9Q23C"
      },
      "source": [
        "history = DeNoise_v1.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d1wxkoMQGvk"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgKOXTBNQ93a"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tw8aA8_8RByR"
      },
      "source": [
        "loss_acc= DeNoise_v1.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pBHF3s2Q91Q"
      },
      "source": [
        "test_predict = DeNoise_v1.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNhhK8dfRcCm"
      },
      "source": [
        "# Image Denoising Auto Encoder case2(Optimizer : ADAM, Learning rate : 0.001, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGjs9kjGQ9yZ"
      },
      "source": [
        "DeNoise_v2 = keras.Model(encoder_input, decoder_output)\n",
        "DeNoise_v2.compile(optimizer=keras.optimizers.ADAM(lr = 0.001), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVTIyLZpO1Cj"
      },
      "source": [
        "history = DeNoise_v2.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_8notjQRy61"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MXuH1eoRy4k"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SV-24Mn_Ry1u"
      },
      "source": [
        "loss_acc= DeNoise_v2.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4T7bFE4pRyyn"
      },
      "source": [
        "test_predict = DeNoise_v2.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ3gSghGR7s0"
      },
      "source": [
        "# Image Denoising Auto Encoder case3(Optimizer : RMSProp, Learning rate : 0.001, Batch Size : 32)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqZyJHITSMKT"
      },
      "source": [
        "DeNoise_v3 = keras.Model(encoder_input, decoder_output)\n",
        "DeNoise_v3.compile(optimizer=keras.optimizers.RMSProp(lr = 0.001), loss='mse', metrics=[SSIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qkY9wDsSMH9"
      },
      "source": [
        "history = DeNoise_v3.fit(train_mask_image, train_image, validation_data=(val_mask_image, val_image), verbose=0, batch_size=32, epochs=100 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6cWlBeaSMET"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATYn_6pCSMBh"
      },
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.epoch, history.history['loss'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_loss'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('Loss(MSE)')\n",
        "#plt.yticks(np.arange(0, 0.05, 5))\n",
        "plt.yticks(np.arange(0, 0.1, 0.01))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('MSE', fontsize=15)\n",
        "\n",
        "plt.grid(alpha=0.3)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.epoch, history.history['SSIM'], label = 'train', color = 'gray', linewidth=2)\n",
        "plt.plot(history.epoch, history.history['val_SSIM'], label = 'validation', color = 'pink', linewidth = 3)\n",
        "plt.title('SSIM')\n",
        "\n",
        "plt.yticks(np.arange(0.6, 1, 0.05))\n",
        "\n",
        "plt.xlabel('Epochs',fontsize=15)\n",
        "plt.ylabel('SSIM', fontsize=15)\n",
        "#plt.yticks(np.arange(0, 0.1, 5))\n",
        "#plt.yticks(np.arange(0, 11, 1))\n",
        "plt.grid(alpha=0.3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPgXfOBQSYS5"
      },
      "source": [
        "loss_acc= DeNoise_v3.evaluate(test_mask_image, test_image)\n",
        "print(\"MSE: \",loss_acc[0])\n",
        "print('SSIM: ', (loss_acc[1],2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8vPVKZ2SYQN"
      },
      "source": [
        "test_predict = DeNoise_v3.predict(test_image)\n",
        "plot_image_pair_test(test_predict, 1,20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}